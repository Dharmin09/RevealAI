# src/core/train_video.py
import argparse
import json
import os

import numpy as np
from tensorflow.keras.applications import Xception
from tensorflow.keras.layers import Dropout, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tqdm.keras import TqdmCallback

from core.config import IMG_SIZE_VIDEO, MODELS_DIR, VIDEO_MODEL_PATH, SPLITS_DIR
from core.utils import preprocess_frames_for_xception

DEFAULT_BATCH_SIZE = 8
DEFAULT_EPOCHS = 1

def build_model(num_classes=2, lr=1e-4):
    base = Xception(weights='imagenet', include_top=False, pooling='avg',
                    input_shape=(IMG_SIZE_VIDEO[0], IMG_SIZE_VIDEO[1], 3))
    x = base.output
    x = Dropout(0.3)(x)
    preds = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=base.input, outputs=preds)

    for layer in base.layers[:-50]:
        layer.trainable = False
    for layer in base.layers[-50:]:
        layer.trainable = True

    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])
    return model


def load_split(split_file):
    items = []
    with open(split_file, "r") as f:
        for line in f:
            path, label = line.strip().split()
            label = 0 if label.lower() in ["real", "bonafide", "0"] else 1
            items.append((path, label))
    return items


def make_generator(items, target_size, batch_size, shuffle=True):
    n = len(items)
    while True:
        if shuffle:
            np.random.shuffle(items)
        for i in range(0, n, batch_size):
            batch_items = items[i:i+batch_size]
            X, y = [], []
            for path, label in batch_items:
                img = load_img(path, target_size=target_size)
                img_arr = img_to_array(img)
                X.append(img_arr)
                onehot = np.zeros(2)
                onehot[label] = 1
                y.append(onehot)
            X_processed = preprocess_frames_for_xception(np.array(X))
            yield X_processed, np.array(y)


def parse_args():
    parser = argparse.ArgumentParser(
        description="Train video deepfake detector with optional correction data",
    )
    parser.add_argument(
        "--corrections-json",
        type=str,
        default=None,
        help="Path to corrections JSON generated by the continuous learning system",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=DEFAULT_EPOCHS,
        help="Number of epochs to train",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=DEFAULT_BATCH_SIZE,
        help="Mini-batch size",
    )
    return parser.parse_args()


def load_corrections(json_path):
    if not json_path:
        return []
    if not os.path.exists(json_path):
        print(f"‚ö†Ô∏è Corrections file not found: {json_path}")
        return []
    try:
        with open(json_path, "r", encoding="utf-8") as handle:
            entries = json.load(handle)
    except Exception as exc:
        print(f"‚ö†Ô∏è Failed to load corrections file {json_path}: {exc}")
        return []

    corrections = []
    for item in entries:
        if item.get("type") not in (None, "video", "unknown"):
            continue
        file_path = item.get("file")
        label = item.get("label")
        if not file_path or not os.path.exists(file_path):
            continue
        try:
            label_int = int(label)
        except (TypeError, ValueError):
            continue
        corrections.append((file_path, label_int))
    if corrections:
        print(f"üîÅ Loaded {len(corrections)} correction samples for video retraining")
    return corrections


def main(cli_args=None):
    args = cli_args or parse_args()

    train_items = load_split(os.path.join(SPLITS_DIR, "video_train.txt"))
    val_items   = load_split(os.path.join(SPLITS_DIR, "video_val.txt"))
    test_items  = load_split(os.path.join(SPLITS_DIR, "video_test.txt"))

    correction_items = load_corrections(args.corrections_json)
    if correction_items:
        train_items.extend(correction_items)

    batch_size = max(1, args.batch_size)

    train_gen = make_generator(train_items, IMG_SIZE_VIDEO, batch_size, shuffle=True)
    val_gen   = make_generator(val_items, IMG_SIZE_VIDEO, batch_size, shuffle=False)
    test_gen  = make_generator(test_items, IMG_SIZE_VIDEO, batch_size, shuffle=False)
    
    steps_train = max(1, len(train_items) // batch_size)
    steps_val   = max(1, len(val_items) // batch_size)
    steps_test  = max(1, len(test_items) // batch_size)

    os.makedirs(MODELS_DIR, exist_ok=True)

    print("üöÄ Starting training from scratch...")
    model = build_model()

    chk = ModelCheckpoint(VIDEO_MODEL_PATH, monitor='val_accuracy', save_best_only=True, verbose=0)
    rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)

    model.fit(
        train_gen,
        steps_per_epoch=steps_train,
        validation_data=val_gen,
        validation_steps=steps_val,
        epochs=max(1, args.epochs),
        callbacks=[chk, rlr, TqdmCallback(verbose=2)],
        verbose=0,
    )

    print("\n‚úÖ Training finished. Best model saved to:", VIDEO_MODEL_PATH)

    print("\nüîé Evaluating on test set...")
    loss, acc = model.evaluate(test_gen, steps=steps_test, verbose=1)
    print(f"\nTest accuracy: {acc:.4f}")


if __name__ == "__main__":
    main()